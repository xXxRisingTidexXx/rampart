{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8svmUftZOtL"
   },
   "source": [
    "![Rampart Logo](../images/logo.png)\n",
    "\n",
    "Auge is an image classification model. Its main target's to recognize common photos to determine a few flat publication's features. Each image belongs to a specific realty, having a bunch of photo & panorama recognized **twinkle** can better predict apartments' order.\n",
    "\n",
    "## I/O\n",
    "Required images lie at `../scientific/images` . Currently the DB containes images of two types: simple photos & wide (360 deg) panoramas. Until a stable classification model panoramas should be omitted. Final classifier must be stored into `../models/auge.latest.pth` .\n",
    "\n",
    "## Classes\n",
    "- `luxury` is a flat with rich furniture, huge rooms, chandeliers, fireplaces, etc.\n",
    "\n",
    "![Luxury 1](../images/luxury1.webp)\n",
    "![Luxury 2](../images/luxury2.webp)\n",
    "![Luxury 3](../images/luxury3.webp)\n",
    "\n",
    "- `comfort` is the most suitable for an ordinary citizen apartments. Clean, neat, sometimes minimalistic, average area, qualitive furniture, etc.\n",
    "\n",
    "![Comfort 1](../images/comfort1.webp)\n",
    "![Comfort 2](../images/comfort2.webp)\n",
    "![Comfort 3](../images/comfort3.webp)\n",
    "\n",
    "- `junk` is an old flat image. Probably, the whole apartments should belong to a dormitory, Khrushchevka or gostinka.\n",
    "\n",
    "![Junk 1](../images/junk1.webp)\n",
    "![Junk 2](../images/junk2.webp)\n",
    "![Junk 3](../images/junk3.webp)\n",
    "\n",
    "- `construction` is a flat without a finished design. No doors, floor, supplies, wallpapers, ceiling, furniture, etc. Typically, new buildings contain these apartments.\n",
    "\n",
    "![Construction 1](../images/construction1.webp)\n",
    "![Construction 2](../images/construction2.webp)\n",
    "![Construction 3](../images/construction3.webp)\n",
    "\n",
    "- `excess` is the trash category. Actually, all exterior photos, outlines & posters lie here.\n",
    "\n",
    "![Excess 1](../images/excess1.webp)\n",
    "![Excess 2](../images/excess2.webp)\n",
    "![Excess 3](../images/excess3.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dV3cYDlZOtL"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPF82oNZZOtL"
   },
   "outputs": [],
   "source": [
    "from plotly.graph_objs import Pie, Figure, Scatter\n",
    "from plotly.figure_factory import create_annotated_heatmap\n",
    "from plotly.express import imshow\n",
    "from plotly.subplots import make_subplots\n",
    "from re import match\n",
    "from numpy import arange, trace, sum\n",
    "from glob import glob\n",
    "from pandas import DataFrame, concat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
    "from torch.nn import Module, Conv2d, Linear, ReLU, CrossEntropyLoss, Sequential, MaxPool2d, Dropout\n",
    "from torch.optim import Adam\n",
    "from torch import no_grad, save, max, load, zeros, cat, long, device, set_num_threads, get_num_threads\n",
    "from uuid import uuid4\n",
    "from PIL.Image import open\n",
    "from multiprocessing import cpu_count\n",
    "from IPython.display import display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_num_threads(cpu_count())\n",
    "print(f'Set thread number to {get_num_threads()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(x):\n",
    "    imshow(x.permute(1, 2, 0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8y1Ga1pjZOtN"
   },
   "outputs": [],
   "source": [
    "labels = ['luxury', 'comfort', 'junk', 'construction', 'excess']\n",
    "mappings = {l: i for i, l in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PjyYwYQZOtN"
   },
   "outputs": [],
   "source": [
    "def label(path):\n",
    "    result = match(r'^.*/\\w+\\.\\w+\\.(\\w+)\\.webp$', path)\n",
    "    if not result:\n",
    "        raise RuntimeError(f'Got invalid path, {path}')\n",
    "    mark = result.groups()[0]\n",
    "    if mark not in mappings:\n",
    "        raise RuntimeError(f'Got invalid label, {path}')\n",
    "    return mappings[mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1uECwIQZOtN"
   },
   "outputs": [],
   "source": [
    "images = DataFrame({'path': glob('../scientific/images/*.webp')})\n",
    "images['label'] = images['path'].apply(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lM4e4XoVZOtO"
   },
   "outputs": [],
   "source": [
    "counts = images['label'].value_counts().sort_index()\n",
    "figure = Figure()\n",
    "figure.add_trace(Pie(labels=[labels[i] for i in counts.index], values=counts.values))\n",
    "figure.update_layout(margin={'t': 30, 'r': 0, 'b': 0, 'l': 0})\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XccA9INZOtP"
   },
   "outputs": [],
   "source": [
    "class AugeDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self._data = data.values\n",
    "        self._transforms = Compose(\n",
    "            [\n",
    "                ToTensor(),\n",
    "                Resize((460, 620)),\n",
    "                Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, label = self._data[index]\n",
    "        return self._transforms(open(path)), label, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYuzSQPtZOtP"
   },
   "outputs": [],
   "source": [
    "training_images, testing_images = train_test_split(images, test_size=0.2)\n",
    "training_images, validation_images = train_test_split(training_images, test_size=0.1)\n",
    "batch_size = 8\n",
    "training_loader = DataLoader(AugeDataset(training_images), batch_size, True)\n",
    "validation_loader = DataLoader(AugeDataset(validation_images), batch_size)\n",
    "testing_loader = DataLoader(AugeDataset(testing_images), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_loader), len(validation_loader), len(testing_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J96sq0_wZOtP"
   },
   "outputs": [],
   "source": [
    "class View(Module):\n",
    "    def __init__(self, *shape):\n",
    "        super().__init__()\n",
    "        self._shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self._shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6l9tsC30ZOtP"
   },
   "outputs": [],
   "source": [
    "class Auge(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._sequential = Sequential(\n",
    "            Conv2d(3, 3, 5, padding=2),\n",
    "            ReLU(),\n",
    "            View(-1, 855600),\n",
    "            Linear(855600, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._sequential(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyuIm8bcYjix"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    auge = Auge()\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = Adam(auge.parameters())\n",
    "    epoch_number = 1\n",
    "    epochs = arange(epoch_number)\n",
    "    training_losses = [0.0] * epoch_number\n",
    "    validation_losses = [0.0] * epoch_number\n",
    "    for epoch in epochs:\n",
    "        auge.train()\n",
    "        for batch in training_loader:\n",
    "            samples, targets = batch[0], batch[1]\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(auge(samples), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_losses[epoch] += loss.item() * samples.size(0)\n",
    "        training_losses[epoch] /= len(training_loader.sampler)\n",
    "        auge.eval()\n",
    "        with no_grad():\n",
    "            for batch in validation_loader:\n",
    "                samples, targets = batch[0], batch[1]\n",
    "                validation_losses[epoch] += criterion(auge(samples), targets).item() * samples.size(0)\n",
    "        validation_losses[epoch] /= len(validation_loader.sampler)\n",
    "    state = auge.state_dict()\n",
    "    save(state, f'../scientific/models/auge.{uuid4().hex}.pth')\n",
    "    save(state, '../scientific/models/auge.latest.pth')\n",
    "    figure = Figure()\n",
    "    figure.add_trace(Scatter(x=epochs, y=training_losses, name='Training'))\n",
    "    figure.add_trace(Scatter(x=epochs, y=validation_losses, name='Validation'))\n",
    "    figure.show()\n",
    "    return auge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2sQ7bTE_ZOtP"
   },
   "outputs": [],
   "source": [
    "def use(tag='latest'):\n",
    "    auge = Auge()\n",
    "    auge.load_state_dict(load(f'../scientific/models/auge.{tag}.pth'))\n",
    "    return auge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbwrWZ7WZOtQ"
   },
   "outputs": [],
   "source": [
    "def test(auge):\n",
    "    auge.eval()\n",
    "    actual, expected = zeros(0, dtype=long), zeros(0, dtype=long)\n",
    "    with no_grad():\n",
    "        for batch in testing_loader:\n",
    "            actual = cat([actual, max(auge(batch[0]), 1)[1].view(-1)])\n",
    "            expected = cat([expected, batch[1].view(-1)])\n",
    "    matrix = confusion_matrix(expected, actual)\n",
    "    figure = create_annotated_heatmap(z=matrix, x=labels, y=labels, hoverinfo='skip')\n",
    "    figure.update_xaxes(title_text='Expected')\n",
    "    figure.update_yaxes(title_text='Actual', autorange='reversed')\n",
    "    figure.update_layout(title=f'Accuracy: {trace(matrix) / sum(matrix) * 100:.2f}%')\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(auge, offset=0, count=10):\n",
    "    portion = count * batch_size\n",
    "    loader = DataLoader(\n",
    "        AugeDataset(testing_images.iloc[offset * portion : (offset + 1) * portion]), \n",
    "        batch_size\n",
    "    )\n",
    "    auge.eval()\n",
    "    with no_grad():\n",
    "        for batch in loader:\n",
    "            for result in zip(max(auge(batch[0]), 1)[1], batch[1], batch[2]): \n",
    "                if result[0] != result[1]:\n",
    "                    print(f'Actual {labels[result[0]]}, expected {labels[result[1]]}')\n",
    "                    display(open(result[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TS7CfNd6aSqM",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for _ in range(1):\n",
    "    test(train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test(use())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explain(use(), 0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "auge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
